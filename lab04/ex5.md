### Exercise 5

##### 1. There are many types of issues which may result in an incorrect measurement. For example, system background processes can temporarily slow down execution. Another example would be CPU performance fluctuations as the processor may adjust its speed because of thermal throttling or power-saving modes. A third example would be garbage collection from languages such as Python can introdue unexpected delays. Lastly, some executions may be faster after the first run due to optimizations (JIT compilation and caching). The timeit approach attempts to address these issues as it runs the code a specific number of times (using the number parameter) and returns a single time value. This ultimately enables reducing short-term fluctuations by averaging over many iterations. The repeat approach attempts to address these issues as it runs timeit.timeit() multiple times (using the repeat parameter) which captures several independent timing results. This uultimately detects variations in execution time due to external factors like system load changes. It is appropriate to use the timeit approach for quick, approximate timing when system conditions are stable. It is appropriate to use the repeat approach when it comes to fluctuating system conditions for more reliable benchmarking (so you can measure the variability in execution time).

##### 2. So the three statistics average, min, and max represent the typical, fastest, abd slowest execution times, respectively. The most appopriate statistic to apply to the output of timeit.timeit() is the min statistic. The reason for this is because since timeit.timeit() executes many times in a single run, the smallest value is the least affected by external disturbances in the system and represents the best-case execution time. The most appropriate statistic to apply to the output of timeit.repeat() is the min or average statistic. For min, it displays the best-case performance, which avoids temporary slowdowns. For average, if the performance varies signifiacntly between repeats, the average provides the better overall picture. The max statistic is not appropriate for either approaches because it is most likely inflated by system interruptions rather than actual code performance.
